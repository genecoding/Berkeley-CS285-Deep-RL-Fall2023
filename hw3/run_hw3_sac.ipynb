{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f767a444-4f0d-4e37-95d4-ee008aae0c05",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e359397e-9e7d-4093-b96e-1fc66205dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958281e8-aecf-440f-965b-1865c9d3839e",
   "metadata": {},
   "source": [
    "# 3.1.1 Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07161217-2386-4d5c-9d4a-722d3110093e",
   "metadata": {},
   "source": [
    "* (Testing) Train an agent on Pendulum-v1 with the sample configuration experiments/sac/sanity_pendulum.yaml. It shouldn’t get high reward yet (you’re not training an actor), but the Q-values should stabilize at some large negative number. The “do-nothing” reward for this environment is about -10 per step; you can use that together with the discount factor γ to calculate (approximately) what Q should be. If the Q-values go to minus infinity or stay close to zero, you probably have a bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0be071c-4978-40dc-b3a3-f8b42ef3be67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/sanity_pendulum.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='sanity_pendulum_no-entropy_hard-update', video_log_freq=-1)\n",
      "{'exp_name': 'sanity_pendulum_no-entropy_hard-update', 'total_steps': 300000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': False, 'target_update_period': 1000, 'soft_target_update_rate': None, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': False, 'temperature': 0.1, 'log_string': 'sanity_pendulum_no-entropy_hard-update_Pendulum-v1', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Pendulum-v1', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/sanity_pendulum_no-entropy_hard-update_Pendulum-v1\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1175.9034423828125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 264.9200744628906\n",
      "eval/return_max : -859.0715942382812\n",
      "eval/return_min : -1607.9176025390625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 44.25908422470093\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1134.56689453125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 224.155517578125\n",
      "eval/return_max : -764.095458984375\n",
      "eval/return_min : -1502.0361328125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 106.40480351448059\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1347.0654296875\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 292.3335266113281\n",
      "eval/return_max : -879.9373779296875\n",
      "eval/return_min : -1749.521484375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 169.28047728538513\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 120000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1254.184326171875\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 300.9684143066406\n",
      "eval/return_max : -766.50927734375\n",
      "eval/return_min : -1743.334716796875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 234.4948480129242\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 150000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1140.846923828125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 293.45806884765625\n",
      "eval/return_max : -815.7420043945312\n",
      "eval/return_min : -1690.5831298828125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 300.85083198547363\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 180000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1136.3746337890625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 358.93768310546875\n",
      "eval/return_max : -757.271240234375\n",
      "eval/return_min : -1752.3834228515625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 367.315550327301\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 210000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1360.6107177734375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 305.7015075683594\n",
      "eval/return_max : -912.7891845703125\n",
      "eval/return_min : -1771.703125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 431.52641892433167\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 240000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1467.13671875\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 297.1932067871094\n",
      "eval/return_max : -738.716796875\n",
      "eval/return_min : -1817.644775390625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 491.5392246246338\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 270000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1218.5894775390625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 275.69195556640625\n",
      "eval/return_max : -814.5416259765625\n",
      "eval/return_min : -1669.0247802734375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 550.8430078029633\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1118.708984375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 278.319580078125\n",
      "eval/return_max : -864.0800170898438\n",
      "eval/return_min : -1681.5853271484375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 612.6988792419434\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test hard update; didn't update actor\n",
    "# set use_entropy_bonus=False, use_soft_target_update=False(default) in sanity_pendulum.yaml\n",
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/sanity_pendulum.yaml \\\n",
    "    --exp_name sanity_pendulum_no-entropy_hard-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2218363f-7eda-4f56-850c-0ca0cda2255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/sanity_pendulum.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='sanity_pendulum_no-entropy_soft-update', video_log_freq=-1)\n",
      "{'exp_name': 'sanity_pendulum_no-entropy_soft-update', 'total_steps': 300000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': False, 'temperature': 0.1, 'log_string': 'sanity_pendulum_no-entropy_soft-update_Pendulum-v1', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Pendulum-v1', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/sanity_pendulum_no-entropy_soft-update_Pendulum-v1\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1400.2913818359375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 300.0461120605469\n",
      "eval/return_max : -974.32470703125\n",
      "eval/return_min : -1758.0025634765625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 46.482889890670776\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1250.5556640625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 287.00848388671875\n",
      "eval/return_max : -809.6566162109375\n",
      "eval/return_min : -1759.603759765625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 115.16633343696594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1225.999267578125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 295.1549377441406\n",
      "eval/return_max : -845.163818359375\n",
      "eval/return_min : -1743.19140625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 180.5898835659027\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 120000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1069.703369140625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 163.6919403076172\n",
      "eval/return_max : -834.672607421875\n",
      "eval/return_min : -1327.5997314453125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 246.40157103538513\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 150000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1418.8048095703125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 303.8582763671875\n",
      "eval/return_max : -905.7513427734375\n",
      "eval/return_min : -1767.174560546875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 311.7272746562958\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 180000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1358.97705078125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 347.8763732910156\n",
      "eval/return_max : -744.1319580078125\n",
      "eval/return_min : -1770.802734375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 377.08134627342224\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 210000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1270.542236328125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 258.0329284667969\n",
      "eval/return_max : -752.9661254882812\n",
      "eval/return_min : -1685.655029296875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 442.9459373950958\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 240000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1319.6136474609375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 246.32313537597656\n",
      "eval/return_max : -895.7669067382812\n",
      "eval/return_min : -1634.9154052734375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 507.9681966304779\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 270000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1215.405029296875\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 258.85882568359375\n",
      "eval/return_max : -893.9942626953125\n",
      "eval/return_min : -1613.1251220703125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 572.4801607131958\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1304.411376953125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 340.8349914550781\n",
      "eval/return_max : -822.9700317382812\n",
      "eval/return_min : -1804.703857421875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 637.9765160083771\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test soft update; didn't update actor\n",
    "# set use_entropy_bonus=False, use_soft_target_update=True in sanity_pendulum.yaml\n",
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/sanity_pendulum.yaml \\\n",
    "    --exp_name sanity_pendulum_no-entropy_soft-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58c870-4892-4efe-b6e8-89b334586fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49366333-bded-4ff0-83c9-79085fe72a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir data/hw3_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e48cc-e882-4c6e-a1af-22139bfece36",
   "metadata": {},
   "source": [
    "# 3.1.2 Entropy Bonus and Soft Actor-Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807fbcf-aad8-4cb0-a4e4-48fb3cd33089",
   "metadata": {},
   "source": [
    "* (Testing) The code should be logging entropy during the critic updates. If you run sanity_pendulum.yaml from before, it should achieve (close to) the maximum possible entropy for a 1-dimensional action space. Entropy is maximized by a uniform distribution:  \n",
    "$$ \\mathcal{H}(\\mathcal{U}[−1, 1]) = \\Bbb{E}[− \\log p(x)] = − \\log \\frac{1}{2} = \\log 2 ≈ 0.69 $$\n",
    "Because currently our actor loss **only** consists of the entropy bonus (we haven’t implemented anything to maximize rewards yet), the entropy should increase until it arrives at roughly this level.  \n",
    "If your logged entropy is higher than this, or significantly lower, you have a bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "769545b1-cf7f-4849-abd7-7687ce3cec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/sanity_pendulum.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'sanity_pendulum', 'total_steps': 300000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': False, 'target_update_period': 1000, 'soft_target_update_rate': None, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.1, 'log_string': 'sanity_pendulum_Pendulum-v1', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Pendulum-v1', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/sanity_pendulum_Pendulum-v1\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1282.138427734375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 338.0502624511719\n",
      "eval/return_max : -742.31396484375\n",
      "eval/return_min : -1768.928955078125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 45.5824933052063\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1243.52392578125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 265.5425720214844\n",
      "eval/return_max : -871.7365112304688\n",
      "eval/return_min : -1751.9168701171875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 110.02885103225708\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1152.29833984375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 239.2854461669922\n",
      "eval/return_max : -859.5940551757812\n",
      "eval/return_min : -1631.0628662109375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 174.29066634178162\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 120000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1298.727294921875\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 202.95921325683594\n",
      "eval/return_max : -938.7412109375\n",
      "eval/return_min : -1667.5465087890625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 239.22070217132568\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 150000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1203.2901611328125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 303.8353576660156\n",
      "eval/return_max : -775.9314575195312\n",
      "eval/return_min : -1653.15478515625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 306.907559633255\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 180000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1312.32080078125\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 207.73849487304688\n",
      "eval/return_max : -983.2525634765625\n",
      "eval/return_min : -1672.8387451171875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 372.878545999527\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 210000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1222.752197265625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 244.2919158935547\n",
      "eval/return_max : -743.0416870117188\n",
      "eval/return_min : -1626.7779541015625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 439.18439745903015\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 240000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1168.3548583984375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 270.3597717285156\n",
      "eval/return_max : -919.4741821289062\n",
      "eval/return_min : -1692.6768798828125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 506.00839591026306\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 270000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1205.314697265625\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 233.44876098632812\n",
      "eval/return_max : -753.2828979492188\n",
      "eval/return_min : -1600.5609130859375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 571.9627611637115\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -1402.9505615234375\n",
      "eval_ep_len : 200.0\n",
      "eval/return_std : 284.1048583984375\n",
      "eval/return_max : -920.7293090820312\n",
      "eval/return_min : -1784.1829833984375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 200\n",
      "eval/ep_len_min : 200\n",
      "TimeSinceStart : 637.0304682254791\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test entropy; didn't update actor\n",
    "# set use_entropy_bonus=True(default), use_soft_target_update=False(default) in sanity_pendulum.yaml\n",
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/sanity_pendulum.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f8417-8a69-4e5f-9620-ea8b40690901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f71b26-6446-426e-b3cb-479a084209ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir data/hw3_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97c622-546e-43bc-8f24-c205a29c077a",
   "metadata": {},
   "source": [
    "# 3.1.3 Actor with REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9c3bf-419d-4ddd-8130-fd052d73a91b",
   "metadata": {},
   "source": [
    "* (Testing) Train an agent on InvertedPendulum-v4 using sanity_invertedpendulum_reinforce.yaml. You should achieve reward close to 1000, which corresponds to staying upright for all time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f726447-8b2f-4d4a-b1d6-3e05d6c312a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/sanity_invertedpendulum_reinforce.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'sanity_invpendulum_reinforce', 'total_steps': 300000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': False, 'target_update_period': 1000, 'soft_target_update_rate': None, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.1, 'log_string': 'sanity_invpendulum_reinforce_InvertedPendulum-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'InvertedPendulum-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/sanity_invpendulum_reinforce_InvertedPendulum-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 97.0999984741211\n",
      "eval_ep_len : 97.1\n",
      "eval/return_std : 34.50347900390625\n",
      "eval/return_max : 187.0\n",
      "eval/return_min : 66.0\n",
      "eval/ep_len_std : 34.50347808554958\n",
      "eval/ep_len_max : 187\n",
      "eval/ep_len_min : 66\n",
      "TimeSinceStart : 80.87066268920898\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 204.45359349250793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 49.400001525878906\n",
      "eval_ep_len : 49.4\n",
      "eval/return_std : 13.74190616607666\n",
      "eval/return_max : 64.0\n",
      "eval/return_min : 18.0\n",
      "eval/ep_len_std : 13.741906709041508\n",
      "eval/ep_len_max : 64\n",
      "eval/ep_len_min : 18\n",
      "TimeSinceStart : 328.4969735145569\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 120000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 111.4000015258789\n",
      "eval_ep_len : 111.4\n",
      "eval/return_std : 8.685620307922363\n",
      "eval/return_max : 122.0\n",
      "eval/return_min : 91.0\n",
      "eval/ep_len_std : 8.685620300243386\n",
      "eval/ep_len_max : 122\n",
      "eval/ep_len_min : 91\n",
      "TimeSinceStart : 452.46467208862305\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 150000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 288.70001220703125\n",
      "eval_ep_len : 288.7\n",
      "eval/return_std : 250.6224365234375\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 113.0\n",
      "eval/ep_len_std : 250.62244512413486\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 113\n",
      "TimeSinceStart : 574.9573051929474\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 180000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 700.65376329422\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 210000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 824.3250410556793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 240000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 987.5999755859375\n",
      "eval_ep_len : 987.6\n",
      "eval/return_std : 37.20000076293945\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 876.0\n",
      "eval/ep_len_std : 37.2\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 876\n",
      "TimeSinceStart : 947.3882074356079\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 270000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1073.0438675880432\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 905.7999877929688\n",
      "eval_ep_len : 905.8\n",
      "eval/return_std : 253.12319946289062\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 151.0\n",
      "eval/ep_len_std : 253.12321110478985\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 151\n",
      "TimeSinceStart : 1199.1702477931976\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/sanity_invertedpendulum_reinforce.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad88795-0381-48b1-92cd-065f166b47b6",
   "metadata": {},
   "source": [
    "* Train an agent on HalfCheetah-v4 using the provided config (halfcheetah_reinforce1.yaml). Note that this configuration uses only one sampled action per training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002c2958-150e-45ab-9046-8716dff4434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/halfcheetah_reinforce1.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'halfcheetah_reinforce1', 'total_steps': 1000000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.2, 'log_string': 'halfcheetah_reinforce1_HalfCheetah-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'HalfCheetah-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/halfcheetah_reinforce1_HalfCheetah-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 109.86601257324219\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 136.73130798339844\n",
      "eval/return_max : 304.6824035644531\n",
      "eval/return_min : -193.772705078125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 456.10518050193787\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 200000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 75.71003723144531\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 92.99344635009766\n",
      "eval/return_max : 193.24183654785156\n",
      "eval/return_min : -124.16804504394531\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 959.2069442272186\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 144.67428588867188\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 23.070371627807617\n",
      "eval/return_max : 189.25405883789062\n",
      "eval/return_min : 115.68881225585938\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1462.9804883003235\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 400000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : -83.59889221191406\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 92.63697814941406\n",
      "eval/return_max : 58.05880355834961\n",
      "eval/return_min : -205.24081420898438\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1947.81183552742\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 23.99088478088379\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 54.357547760009766\n",
      "eval/return_max : 110.67945861816406\n",
      "eval/return_min : -66.06119537353516\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2435.3090558052063\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 600000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 650.7334594726562\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 181.33987426757812\n",
      "eval/return_max : 893.6734619140625\n",
      "eval/return_min : 253.33038330078125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2921.694825410843\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 700000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 529.5159912109375\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 408.1415710449219\n",
      "eval/return_max : 1206.21240234375\n",
      "eval/return_min : 59.869293212890625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3407.578515291214\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 800000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 683.2372436523438\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 92.05812072753906\n",
      "eval/return_max : 789.5855102539062\n",
      "eval/return_min : 528.6719360351562\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3893.1321413517\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 900000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 995.1248779296875\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 63.887420654296875\n",
      "eval/return_max : 1079.4840087890625\n",
      "eval/return_min : 880.506591796875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 4379.395779132843\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 1000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1101.7281494140625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 640.7770385742188\n",
      "eval/return_max : 1700.895751953125\n",
      "eval/return_min : -139.74256896972656\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 4864.224642038345\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/halfcheetah_reinforce1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd579d-c913-4f18-b331-95d3d0f4999b",
   "metadata": {},
   "source": [
    "* Train another agent with halfcheetah_reinforce10.yaml. This configuration takes many samples from the actor for computing the REINFORCE gradient (we’ll call this REINFORCE-10, and the singlesample version REINFORCE-1). Plot the results (evaluation return over time) on the same axes as the single-sample REINFORCE. Compare and explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79674384-8e7a-4892-aebf-8dc3299393c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/halfcheetah_reinforce10.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'halfcheetah_reinforce10', 'total_steps': 1000000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reinforce', 'num_actor_samples': 10, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.2, 'log_string': 'halfcheetah_reinforce10_HalfCheetah-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'HalfCheetah-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/halfcheetah_reinforce10_HalfCheetah-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 63.63093948364258\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 83.39027404785156\n",
      "eval/return_max : 186.97918701171875\n",
      "eval/return_min : -145.67515563964844\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 515.6789767742157\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 200000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 897.43896484375\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 65.33644104003906\n",
      "eval/return_max : 1013.6688232421875\n",
      "eval/return_min : 775.075439453125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1083.6752893924713\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 450.92559814453125\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 486.1508483886719\n",
      "eval/return_max : 1106.9595947265625\n",
      "eval/return_min : -230.08030700683594\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1651.8993611335754\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 400000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 923.291015625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 67.55741119384766\n",
      "eval/return_max : 986.8004760742188\n",
      "eval/return_min : 785.4976806640625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2218.1799833774567\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 598.7916259765625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 141.56314086914062\n",
      "eval/return_max : 776.5470581054688\n",
      "eval/return_min : 238.2130889892578\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2785.5590994358063\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 600000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1885.2904052734375\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 57.18706130981445\n",
      "eval/return_max : 1981.642333984375\n",
      "eval/return_min : 1815.3189697265625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3352.3566880226135\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 700000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1859.496826171875\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 517.3077392578125\n",
      "eval/return_max : 2207.163330078125\n",
      "eval/return_min : 331.344970703125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3920.533025741577\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 800000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1298.2935791015625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 820.9107055664062\n",
      "eval/return_max : 2535.8583984375\n",
      "eval/return_min : 213.1204833984375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 4486.936078548431\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 900000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2034.029541015625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 80.63249206542969\n",
      "eval/return_max : 2150.02001953125\n",
      "eval/return_min : 1911.5072021484375\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 5055.161900758743\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 1000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2254.46728515625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 102.67085266113281\n",
      "eval/return_max : 2393.3798828125\n",
      "eval/return_min : 2047.618408203125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 5621.904688835144\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/halfcheetah_reinforce10.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26b6b7-86a4-4de3-a046-42d091fcb3eb",
   "metadata": {},
   "source": [
    "reinforce10 works better. Because REINFORCE needs more samples to perform better, reinforce10 performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749c7a6-c4bf-49e5-be44-34cfca1a4dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304010e1-d0b2-4c8f-99ee-b20ed0ba488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir data/hw3_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb975f4-8e09-4c7c-aaf7-05c7bdc4be94",
   "metadata": {},
   "source": [
    "# 3.1.4 Actor with REPARAMETRIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383690ef-e28a-448d-820b-19a4df574797",
   "metadata": {},
   "source": [
    "* (Testing) Make sure you can solve InvertedPendulum-v4 (use sanity_invertedpendulum_reparametrize.yaml) and achieve similar reward to the REINFORCE case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab40094-d83a-4de2-9c10-95268b6f9b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/sanity_invertedpendulum_reparametrize.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'sanity_invpendulum_reparametrize', 'total_steps': 300000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': False, 'target_update_period': 1000, 'soft_target_update_rate': None, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.1, 'log_string': 'sanity_invpendulum_reparametrize_InvertedPendulum-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'InvertedPendulum-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/sanity_invpendulum_reparametrize_InvertedPendulum-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 98.69999694824219\n",
      "eval_ep_len : 98.7\n",
      "eval/return_std : 77.96159362792969\n",
      "eval/return_max : 242.0\n",
      "eval/return_min : 7.0\n",
      "eval/ep_len_std : 77.96159310840179\n",
      "eval/ep_len_max : 242\n",
      "eval/ep_len_min : 7\n",
      "TimeSinceStart : 82.34259843826294\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 957.5\n",
      "eval_ep_len : 957.5\n",
      "eval/return_std : 127.5\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 575.0\n",
      "eval/ep_len_std : 127.5\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 575\n",
      "TimeSinceStart : 212.42167925834656\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 346.46981167793274\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 120000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 477.7907962799072\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 150000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 962.5999755859375\n",
      "eval_ep_len : 962.6\n",
      "eval/return_std : 112.20000457763672\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 626.0\n",
      "eval/ep_len_std : 112.19999999999999\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 626\n",
      "TimeSinceStart : 607.770745754242\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 180000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 992.9000244140625\n",
      "eval_ep_len : 992.9\n",
      "eval/return_std : 21.299999237060547\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 929.0\n",
      "eval/ep_len_std : 21.300000000000004\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 929\n",
      "TimeSinceStart : 739.7566204071045\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 210000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 864.0999755859375\n",
      "eval_ep_len : 864.1\n",
      "eval/return_std : 280.9620666503906\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 134.0\n",
      "eval/ep_len_std : 280.9620792918503\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 134\n",
      "TimeSinceStart : 870.3602948188782\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 240000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 914.2999877929688\n",
      "eval_ep_len : 914.3\n",
      "eval/return_std : 194.55079650878906\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 355.0\n",
      "eval/ep_len_std : 194.5507902836686\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 355\n",
      "TimeSinceStart : 1000.6874289512634\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 270000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1000.0\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 0.0\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 1000.0\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1131.6344738006592\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 934.2999877929688\n",
      "eval_ep_len : 934.3\n",
      "eval/return_std : 197.10000610351562\n",
      "eval/return_max : 1000.0\n",
      "eval/return_min : 343.0\n",
      "eval/ep_len_std : 197.1\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 343\n",
      "TimeSinceStart : 1262.7501945495605\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/sanity_invertedpendulum_reparametrize.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b62dc-f023-423a-9f56-4e63d88d628e",
   "metadata": {},
   "source": [
    "* Train (once again) on HalfCheetah-v4 with halfcheetah_reparametrize.yaml. Plot results for all three gradient estimators (REINFORCE-1, REINFORCE-10 samples, and REPARAMETRIZE) on the same set of axes, with number of environment steps on the x-axis and evaluation return on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb30eb0-d58e-4bf4-817c-ff96f7c6a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/halfcheetah_reparametrize.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'halfcheetah_reparametrize', 'total_steps': 1000000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 128, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.1, 'log_string': 'halfcheetah_reparametrize_HalfCheetah-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'HalfCheetah-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/halfcheetah_reparametrize_HalfCheetah-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 957.1510009765625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 240.9503173828125\n",
      "eval/return_max : 1243.3751220703125\n",
      "eval/return_min : 583.72314453125\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 464.1217927932739\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 200000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1186.275390625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 235.63462829589844\n",
      "eval/return_max : 1478.5987548828125\n",
      "eval/return_min : 653.6092529296875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 948.1678502559662\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 300000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 989.5472412109375\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 277.0462646484375\n",
      "eval/return_max : 1357.65380859375\n",
      "eval/return_min : 593.2049560546875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1431.7290244102478\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 400000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1396.631591796875\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 192.7014923095703\n",
      "eval/return_max : 1575.3363037109375\n",
      "eval/return_min : 1001.277587890625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 1916.6228466033936\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1282.773681640625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 223.70811462402344\n",
      "eval/return_max : 1519.4281005859375\n",
      "eval/return_min : 883.572509765625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2401.2673375606537\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 600000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1594.037353515625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 101.22776794433594\n",
      "eval/return_max : 1745.46484375\n",
      "eval/return_min : 1367.8111572265625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 2886.003163099289\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 700000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1360.912353515625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 446.168701171875\n",
      "eval/return_max : 1780.5347900390625\n",
      "eval/return_min : 489.2574157714844\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3371.5251791477203\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 800000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1549.8948974609375\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 286.8688049316406\n",
      "eval/return_max : 1756.7421875\n",
      "eval/return_min : 969.513916015625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 3856.1888766288757\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 900000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1102.029541015625\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 396.823486328125\n",
      "eval/return_max : 1715.157958984375\n",
      "eval/return_min : 713.949462890625\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 4340.735699892044\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 1000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1625.282470703125\n",
      "eval_ep_len : 1000.0\n",
      "eval/return_std : 331.7099914550781\n",
      "eval/return_max : 1895.5313720703125\n",
      "eval/return_min : 751.6112060546875\n",
      "eval/ep_len_std : 0.0\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 1000\n",
      "TimeSinceStart : 4824.873655557632\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/halfcheetah_reparametrize.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ae8f2-1b01-4438-8ba3-837749a47ad6",
   "metadata": {},
   "source": [
    "* Train an agent for the Humanoid-v4 environment with humanoid.yaml and plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96019005-0b4c-473c-9f3d-8750a5032e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/humanoid.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=2, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=1000000)\n",
      "{'exp_name': 'humanoid', 'total_steps': 5000000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 256, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 2, 'target_critic_backup_type': 'min', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.05, 'log_string': 'humanoid_Humanoid-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Humanoid-v4', 'hidden_size': 256, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/humanoid_Humanoid-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 822.974609375\n",
      "eval_ep_len : 164.0\n",
      "eval/return_std : 271.01800537109375\n",
      "eval/return_max : 1247.558349609375\n",
      "eval/return_min : 518.19970703125\n",
      "eval/ep_len_std : 57.619441163551734\n",
      "eval/ep_len_max : 259\n",
      "eval/ep_len_min : 98\n",
      "TimeSinceStart : 8705.027739286423\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 1000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1200.272216796875\n",
      "eval_ep_len : 241.0\n",
      "eval/return_std : 527.2288208007812\n",
      "eval/return_max : 2300.05078125\n",
      "eval/return_min : 510.4092712402344\n",
      "eval/ep_len_std : 111.80697652651197\n",
      "eval/ep_len_max : 484\n",
      "eval/ep_len_min : 95\n",
      "TimeSinceStart : 22100.17286014557\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\envs\\cs285\\lib\\site-packages\\gym\\core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Step 1500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2436.89794921875\n",
      "eval_ep_len : 484.2\n",
      "eval/return_std : 1635.2459716796875\n",
      "eval/return_max : 5105.0830078125\n",
      "eval/return_min : 450.7032165527344\n",
      "eval/ep_len_std : 323.3477385107247\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 90\n",
      "TimeSinceStart : 49007.102304935455\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 2000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3819.98388671875\n",
      "eval_ep_len : 731.5\n",
      "eval/return_std : 1281.099609375\n",
      "eval/return_max : 5213.82373046875\n",
      "eval/return_min : 1239.657470703125\n",
      "eval/ep_len_std : 249.33240864356162\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 224\n",
      "TimeSinceStart : 71976.43786811829\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 2500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2825.539794921875\n",
      "eval_ep_len : 522.5\n",
      "eval/return_std : 1787.7298583984375\n",
      "eval/return_max : 5674.67431640625\n",
      "eval/return_min : 321.5865783691406\n",
      "eval/ep_len_std : 314.23215939811126\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 63\n",
      "TimeSinceStart : 96469.79709219933\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 3000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3457.10595703125\n",
      "eval_ep_len : 647.2\n",
      "eval/return_std : 1675.3343505859375\n",
      "eval/return_max : 5257.69091796875\n",
      "eval/return_min : 694.5419311523438\n",
      "eval/ep_len_std : 323.21967761879847\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 126\n",
      "TimeSinceStart : 120413.60303711891\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 3500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3293.349609375\n",
      "eval_ep_len : 591.8\n",
      "eval/return_std : 1587.9132080078125\n",
      "eval/return_max : 5707.47119140625\n",
      "eval/return_min : 1399.65673828125\n",
      "eval/ep_len_std : 287.11732793406946\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 245\n",
      "TimeSinceStart : 142689.79808974266\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 4000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3065.350341796875\n",
      "eval_ep_len : 568.9\n",
      "eval/return_std : 1718.9400634765625\n",
      "eval/return_max : 5610.513671875\n",
      "eval/return_min : 658.2862548828125\n",
      "eval/ep_len_std : 305.30131018389034\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 145\n",
      "TimeSinceStart : 168696.51967453957\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 4500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3654.900390625\n",
      "eval_ep_len : 649.3\n",
      "eval/return_std : 1960.09912109375\n",
      "eval/return_max : 5754.7080078125\n",
      "eval/return_min : 677.5285034179688\n",
      "eval/ep_len_std : 341.5169249100255\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 144\n",
      "TimeSinceStart : 192891.7990281582\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 5000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3048.0576171875\n",
      "eval_ep_len : 526.2\n",
      "eval/return_std : 1826.275634765625\n",
      "eval/return_max : 5946.126953125\n",
      "eval/return_min : 1240.6732177734375\n",
      "eval/ep_len_std : 308.9543008278085\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 227\n",
      "TimeSinceStart : 217781.21030521393\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# executing for about 60.5 hr (on localhost CPU, i5-12400)\n",
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/humanoid.yaml \\\n",
    "    --video_log_freq 1_000_000 --num_render_trajectories 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93301f3f-4a55-4492-a981-59d1556e3bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d88bb-97b2-47f0-b826-3c07658f792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir data/hw3_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071acef8-dc47-483a-8368-c5b9d8e7ca2a",
   "metadata": {},
   "source": [
    "# 3.1.5 Stabilizing Target Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086613a-8e3d-48df-bac7-9563d78b0a95",
   "metadata": {},
   "source": [
    "* Run single-Q, double-Q, and clipped double-Q on Hopper-v4 using the corresponding configuration files. Which one works best? Plot the logged eval_return from each of them as well as q_values. Discuss how these results relate to overestimation bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6000f3f5-9ad5-4e52-be4b-5578dc50069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/hopper.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'hopper_singlecritic', 'total_steps': 100000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 256, 'replay_buffer_capacity': 100000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 1, 'target_critic_backup_type': 'mean', 'backup_entropy': False, 'use_entropy_bonus': True, 'temperature': 0.05, 'log_string': 'hopper_singlecritic_Hopper-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Hopper-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/hopper_singlecritic_Hopper-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 10000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 13.847628593444824\n",
      "eval_ep_len : 25.3\n",
      "eval/return_std : 5.870682239532471\n",
      "eval/return_max : 27.25314712524414\n",
      "eval/return_min : 6.55082893371582\n",
      "eval/ep_len_std : 8.198170527623832\n",
      "eval/ep_len_max : 38\n",
      "eval/ep_len_min : 14\n",
      "TimeSinceStart : 2.67034649848938\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 20000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 259.3728942871094\n",
      "eval_ep_len : 117.0\n",
      "eval/return_std : 10.734051704406738\n",
      "eval/return_max : 274.47796630859375\n",
      "eval/return_min : 239.9467010498047\n",
      "eval/ep_len_std : 7.483314773547883\n",
      "eval/ep_len_max : 130\n",
      "eval/ep_len_min : 104\n",
      "TimeSinceStart : 51.39038300514221\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 236.47305297851562\n",
      "eval_ep_len : 105.5\n",
      "eval/return_std : 9.552751541137695\n",
      "eval/return_max : 256.95751953125\n",
      "eval/return_min : 221.55287170410156\n",
      "eval/ep_len_std : 1.5652475842498528\n",
      "eval/ep_len_max : 107\n",
      "eval/ep_len_min : 102\n",
      "TimeSinceStart : 101.00689101219177\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 40000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 273.87762451171875\n",
      "eval_ep_len : 112.3\n",
      "eval/return_std : 6.868744373321533\n",
      "eval/return_max : 281.4097900390625\n",
      "eval/return_min : 262.00579833984375\n",
      "eval/ep_len_std : 1.7916472867168916\n",
      "eval/ep_len_max : 115\n",
      "eval/ep_len_min : 109\n",
      "TimeSinceStart : 151.0707471370697\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 50000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 357.3536682128906\n",
      "eval_ep_len : 130.9\n",
      "eval/return_std : 49.530662536621094\n",
      "eval/return_max : 490.0928649902344\n",
      "eval/return_min : 282.9646911621094\n",
      "eval/ep_len_std : 16.458736281987143\n",
      "eval/ep_len_max : 175\n",
      "eval/ep_len_min : 107\n",
      "TimeSinceStart : 200.4393756389618\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 208.8343048095703\n",
      "eval_ep_len : 106.5\n",
      "eval/return_std : 27.218278884887695\n",
      "eval/return_max : 251.7843475341797\n",
      "eval/return_min : 168.1870880126953\n",
      "eval/ep_len_std : 10.413932974625869\n",
      "eval/ep_len_max : 120\n",
      "eval/ep_len_min : 91\n",
      "TimeSinceStart : 249.58399653434753\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 70000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 253.2377471923828\n",
      "eval_ep_len : 100.7\n",
      "eval/return_std : 82.522705078125\n",
      "eval/return_max : 354.7432556152344\n",
      "eval/return_min : 128.539306640625\n",
      "eval/ep_len_std : 22.000227271553356\n",
      "eval/ep_len_max : 122\n",
      "eval/ep_len_min : 66\n",
      "TimeSinceStart : 298.4144871234894\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 80000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 348.35614013671875\n",
      "eval_ep_len : 135.6\n",
      "eval/return_std : 28.5014591217041\n",
      "eval/return_max : 374.1099548339844\n",
      "eval/return_min : 264.8769226074219\n",
      "eval/ep_len_std : 6.135144660071187\n",
      "eval/ep_len_max : 142\n",
      "eval/ep_len_min : 120\n",
      "TimeSinceStart : 348.2587242126465\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 351.0426330566406\n",
      "eval_ep_len : 142.9\n",
      "eval/return_std : 39.170616149902344\n",
      "eval/return_max : 430.3514709472656\n",
      "eval/return_min : 311.3652648925781\n",
      "eval/ep_len_std : 9.565040512198577\n",
      "eval/ep_len_max : 162\n",
      "eval/ep_len_min : 132\n",
      "TimeSinceStart : 396.8432981967926\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 297.636474609375\n",
      "eval_ep_len : 122.7\n",
      "eval/return_std : 12.976551055908203\n",
      "eval/return_max : 322.20513916015625\n",
      "eval/return_min : 282.35809326171875\n",
      "eval/ep_len_std : 3.5227829907617076\n",
      "eval/ep_len_max : 128\n",
      "eval/ep_len_min : 118\n",
      "TimeSinceStart : 446.09107637405396\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/hopper.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e06368-cd7f-430e-8033-e8a9a9fa5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/hopper_doubleq.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'hopper_doubleq', 'total_steps': 100000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 256, 'replay_buffer_capacity': 100000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 2, 'target_critic_backup_type': 'doubleq', 'backup_entropy': False, 'use_entropy_bonus': True, 'temperature': 0.05, 'log_string': 'hopper_doubleq_Hopper-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Hopper-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/hopper_doubleq_Hopper-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 10000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 19.69094467163086\n",
      "eval_ep_len : 30.6\n",
      "eval/return_std : 4.810717582702637\n",
      "eval/return_max : 28.787858963012695\n",
      "eval/return_min : 14.2939453125\n",
      "eval/ep_len_std : 9.189124006128115\n",
      "eval/ep_len_max : 48\n",
      "eval/ep_len_min : 15\n",
      "TimeSinceStart : 2.6585073471069336\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 20000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 211.61807250976562\n",
      "eval_ep_len : 105.0\n",
      "eval/return_std : 12.970057487487793\n",
      "eval/return_max : 234.66705322265625\n",
      "eval/return_min : 197.28733825683594\n",
      "eval/ep_len_std : 2.792848008753788\n",
      "eval/ep_len_max : 111\n",
      "eval/ep_len_min : 102\n",
      "TimeSinceStart : 69.88967084884644\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 296.7899169921875\n",
      "eval_ep_len : 131.3\n",
      "eval/return_std : 38.463321685791016\n",
      "eval/return_max : 353.0112609863281\n",
      "eval/return_min : 228.71421813964844\n",
      "eval/ep_len_std : 7.335529974037323\n",
      "eval/ep_len_max : 145\n",
      "eval/ep_len_min : 116\n",
      "TimeSinceStart : 137.54181480407715\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 40000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 297.80889892578125\n",
      "eval_ep_len : 134.3\n",
      "eval/return_std : 9.249593734741211\n",
      "eval/return_max : 311.00201416015625\n",
      "eval/return_min : 277.2897033691406\n",
      "eval/ep_len_std : 5.1\n",
      "eval/ep_len_max : 143\n",
      "eval/ep_len_min : 124\n",
      "TimeSinceStart : 204.9654233455658\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 50000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 307.5341491699219\n",
      "eval_ep_len : 135.8\n",
      "eval/return_std : 11.163311958312988\n",
      "eval/return_max : 328.9219665527344\n",
      "eval/return_min : 290.4969482421875\n",
      "eval/ep_len_std : 4.874423042781576\n",
      "eval/ep_len_max : 144\n",
      "eval/ep_len_min : 130\n",
      "TimeSinceStart : 272.7535800933838\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 353.5790710449219\n",
      "eval_ep_len : 127.3\n",
      "eval/return_std : 19.2025203704834\n",
      "eval/return_max : 378.2378234863281\n",
      "eval/return_min : 317.13665771484375\n",
      "eval/ep_len_std : 4.859012245302537\n",
      "eval/ep_len_max : 136\n",
      "eval/ep_len_min : 118\n",
      "TimeSinceStart : 340.22691774368286\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 70000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 292.71478271484375\n",
      "eval_ep_len : 116.5\n",
      "eval/return_std : 85.471435546875\n",
      "eval/return_max : 346.3215637207031\n",
      "eval/return_min : 42.02191162109375\n",
      "eval/ep_len_std : 31.152046481732143\n",
      "eval/ep_len_max : 135\n",
      "eval/ep_len_min : 24\n",
      "TimeSinceStart : 407.48264622688293\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 80000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 638.9260864257812\n",
      "eval_ep_len : 226.0\n",
      "eval/return_std : 150.37171936035156\n",
      "eval/return_max : 846.170166015625\n",
      "eval/return_min : 357.731201171875\n",
      "eval/ep_len_std : 41.1849487070216\n",
      "eval/ep_len_max : 273\n",
      "eval/ep_len_min : 150\n",
      "TimeSinceStart : 476.4389877319336\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 287.78778076171875\n",
      "eval_ep_len : 105.4\n",
      "eval/return_std : 202.95582580566406\n",
      "eval/return_max : 517.8118286132812\n",
      "eval/return_min : 45.720909118652344\n",
      "eval/ep_len_std : 65.60060975326373\n",
      "eval/ep_len_max : 177\n",
      "eval/ep_len_min : 26\n",
      "TimeSinceStart : 546.3420269489288\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 509.61749267578125\n",
      "eval_ep_len : 180.3\n",
      "eval/return_std : 34.895957946777344\n",
      "eval/return_max : 569.7739868164062\n",
      "eval/return_min : 452.8168640136719\n",
      "eval/ep_len_std : 8.683893136145793\n",
      "eval/ep_len_max : 199\n",
      "eval/ep_len_min : 164\n",
      "TimeSinceStart : 616.092010974884\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/hopper_doubleq.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8818d223-5947-4930-80a0-9952079e5b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/hopper_clipq.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=0, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=-1)\n",
      "{'exp_name': 'hopper_clipq', 'total_steps': 100000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 256, 'replay_buffer_capacity': 100000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 2, 'target_critic_backup_type': 'min', 'backup_entropy': False, 'use_entropy_bonus': True, 'temperature': 0.05, 'log_string': 'hopper_clipq_Hopper-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Hopper-v4', 'hidden_size': 128, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/hopper_clipq_Hopper-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 10000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 15.078584671020508\n",
      "eval_ep_len : 25.7\n",
      "eval/return_std : 4.516898155212402\n",
      "eval/return_max : 22.11772918701172\n",
      "eval/return_min : 7.368166923522949\n",
      "eval/ep_len_std : 9.317188417113824\n",
      "eval/ep_len_max : 43\n",
      "eval/ep_len_min : 13\n",
      "TimeSinceStart : 2.7649450302124023\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 20000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 221.1159210205078\n",
      "eval_ep_len : 102.1\n",
      "eval/return_std : 4.701300144195557\n",
      "eval/return_max : 229.9913330078125\n",
      "eval/return_min : 213.98011779785156\n",
      "eval/ep_len_std : 1.374772708486752\n",
      "eval/ep_len_max : 105\n",
      "eval/ep_len_min : 100\n",
      "TimeSinceStart : 71.13553404808044\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 30000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 295.1514587402344\n",
      "eval_ep_len : 123.2\n",
      "eval/return_std : 20.22368812561035\n",
      "eval/return_max : 319.1084899902344\n",
      "eval/return_min : 242.376220703125\n",
      "eval/ep_len_std : 6.80881781221968\n",
      "eval/ep_len_max : 131\n",
      "eval/ep_len_min : 106\n",
      "TimeSinceStart : 138.83605885505676\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 40000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 333.4874267578125\n",
      "eval_ep_len : 133.7\n",
      "eval/return_std : 28.90024185180664\n",
      "eval/return_max : 381.7471923828125\n",
      "eval/return_min : 266.73529052734375\n",
      "eval/ep_len_std : 7.211795892841117\n",
      "eval/ep_len_max : 146\n",
      "eval/ep_len_min : 118\n",
      "TimeSinceStart : 207.35365772247314\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 50000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 431.33013916015625\n",
      "eval_ep_len : 182.4\n",
      "eval/return_std : 26.509923934936523\n",
      "eval/return_max : 479.3720397949219\n",
      "eval/return_min : 398.5675964355469\n",
      "eval/ep_len_std : 12.823416081528354\n",
      "eval/ep_len_max : 212\n",
      "eval/ep_len_min : 164\n",
      "TimeSinceStart : 278.67180490493774\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 60000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 460.8793029785156\n",
      "eval_ep_len : 162.3\n",
      "eval/return_std : 49.81096267700195\n",
      "eval/return_max : 570.2239990234375\n",
      "eval/return_min : 401.3570556640625\n",
      "eval/ep_len_std : 13.32704018152568\n",
      "eval/ep_len_max : 190\n",
      "eval/ep_len_min : 147\n",
      "TimeSinceStart : 352.71683859825134\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 70000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 532.8094482421875\n",
      "eval_ep_len : 167.8\n",
      "eval/return_std : 41.996490478515625\n",
      "eval/return_max : 581.8746337890625\n",
      "eval/return_min : 453.5032653808594\n",
      "eval/ep_len_std : 10.656453443805777\n",
      "eval/ep_len_max : 186\n",
      "eval/ep_len_min : 149\n",
      "TimeSinceStart : 425.1322820186615\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 80000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 452.48516845703125\n",
      "eval_ep_len : 165.7\n",
      "eval/return_std : 25.198108673095703\n",
      "eval/return_max : 505.2750244140625\n",
      "eval/return_min : 425.1196594238281\n",
      "eval/ep_len_std : 7.211795892841117\n",
      "eval/ep_len_max : 177\n",
      "eval/ep_len_min : 156\n",
      "TimeSinceStart : 493.4784288406372\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 90000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 553.0126342773438\n",
      "eval_ep_len : 197.9\n",
      "eval/return_std : 57.79808807373047\n",
      "eval/return_max : 705.1781616210938\n",
      "eval/return_min : 486.2733459472656\n",
      "eval/ep_len_std : 16.819334112859522\n",
      "eval/ep_len_max : 243\n",
      "eval/ep_len_min : 180\n",
      "TimeSinceStart : 564.2355489730835\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 100000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 648.5777587890625\n",
      "eval_ep_len : 215.9\n",
      "eval/return_std : 29.3909912109375\n",
      "eval/return_max : 693.7744140625\n",
      "eval/return_min : 603.2373657226562\n",
      "eval/ep_len_std : 4.763402145525822\n",
      "eval/ep_len_max : 223\n",
      "eval/ep_len_min : 210\n",
      "TimeSinceStart : 633.2234683036804\n",
      "Done logging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/hopper_clipq.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3a163-ab88-4d46-bb4b-0870be0d621f",
   "metadata": {},
   "source": [
    "q_value: single-Q > double-Q > clipped double-Q; eval_return: clipped double-Q > double-Q > single-Q. single-Q has an over-estimation issue; double-Q and clipped double-Q can alleviate it quitely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71f999-819f-4e6f-a789-d6214a3e4598",
   "metadata": {},
   "source": [
    "* Pick the best configuration (single-Q/double-Q/clipped double-Q, or REDQ if you implement it) and run it on Humanoid-v4 using humanoid.yaml (edit the config to use the best option). You can truncate it after 500K environment steps. If you got results from the humanoid environment in the last homework, plot them together with environment steps on the x-axis and evaluation return on the y-axis. Otherwise, we will provide a humanoid log file that you can use for comparison. How do the off-policy and on-policy algorithms compare in terms of sample efficiency? *Note: if you’d like to run training to completion (5M steps), you should get a proper, walking humanoid! You can run with videos enabled by using **-nvid 1**. If you run with videos, you can strip videos from the logs for submission with [this script](https://gist.github.com/kylestach/e9964f5f34ee74367547dec83eaf5fae).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08697326-2a9c-4659-b72d-83aca33681f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_file='experiments/sac/humanoid_redq_reparametrize.yaml', eval_interval=5000, num_eval_trajectories=10, num_render_trajectories=2, seed=1, no_gpu=False, which_gpu=0, log_interval=1000, exp_name='', video_log_freq=1000000)\n",
      "{'exp_name': 'humanoid_redq_reparametrize', 'total_steps': 5000000, 'random_steps': 5000, 'training_starts': 10000, 'batch_size': 256, 'replay_buffer_capacity': 1000000, 'ep_len': None, 'discount': 0.99, 'use_soft_target_update': True, 'target_update_period': None, 'soft_target_update_rate': 0.005, 'actor_gradient_type': 'reparametrize', 'num_actor_samples': 1, 'num_critic_updates': 1, 'num_critic_networks': 10, 'target_critic_backup_type': 'redq', 'backup_entropy': True, 'use_entropy_bonus': True, 'temperature': 0.05, 'log_string': 'humanoid_redq_reparametrize_Humanoid-v4', 'actor_fixed_std': None, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'env_name': 'Humanoid-v4', 'hidden_size': 256, 'num_layers': 3, 'use_tanh': True}\n",
      "########################\n",
      "logging outputs to  C:\\Users\\user\\Colab\\Berkeley_DeepRL_Fall2023\\hw3\\cs285\\scripts\\../../data\\hw3_sac/humanoid_redq_reparametrize_Humanoid-v4\n",
      "########################\n",
      "Using CPU.\n",
      "\n",
      "************ Step 500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1304.302490234375\n",
      "eval_ep_len : 256.0\n",
      "eval/return_std : 914.9304809570312\n",
      "eval/return_max : 3875.31640625\n",
      "eval/return_min : 560.662353515625\n",
      "eval/ep_len_std : 179.2562411744707\n",
      "eval/ep_len_max : 757\n",
      "eval/ep_len_min : 104\n",
      "TimeSinceStart : 28355.95621061325\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 1000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1871.9700927734375\n",
      "eval_ep_len : 368.5\n",
      "eval/return_std : 723.897216796875\n",
      "eval/return_max : 3210.12939453125\n",
      "eval/return_min : 766.6636962890625\n",
      "eval/ep_len_std : 140.18933625636438\n",
      "eval/ep_len_max : 622\n",
      "eval/ep_len_min : 153\n",
      "TimeSinceStart : 59974.21864819527\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 1500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1396.4263916015625\n",
      "eval_ep_len : 290.8\n",
      "eval/return_std : 807.6588745117188\n",
      "eval/return_max : 2940.237548828125\n",
      "eval/return_min : 372.88299560546875\n",
      "eval/ep_len_std : 162.75183562712894\n",
      "eval/ep_len_max : 609\n",
      "eval/ep_len_min : 84\n",
      "TimeSinceStart : 100881.77803897858\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 2000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2978.96044921875\n",
      "eval_ep_len : 580.2\n",
      "eval/return_std : 1956.1121826171875\n",
      "eval/return_max : 5256.1787109375\n",
      "eval/return_min : 276.4438171386719\n",
      "eval/ep_len_std : 374.20710843061227\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 55\n",
      "TimeSinceStart : 141467.94875001907\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 2500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3030.27099609375\n",
      "eval_ep_len : 594.8\n",
      "eval/return_std : 1837.632080078125\n",
      "eval/return_max : 5386.3681640625\n",
      "eval/return_min : 145.67160034179688\n",
      "eval/ep_len_std : 338.47800519383827\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 31\n",
      "TimeSinceStart : 185548.68228769302\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 3000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2032.432373046875\n",
      "eval_ep_len : 396.2\n",
      "eval/return_std : 1536.6514892578125\n",
      "eval/return_max : 4988.45361328125\n",
      "eval/return_min : 124.90217590332031\n",
      "eval/ep_len_std : 299.25400582114185\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 25\n",
      "TimeSinceStart : 227869.92986416817\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 3500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 1938.5986328125\n",
      "eval_ep_len : 375.0\n",
      "eval/return_std : 1273.9227294921875\n",
      "eval/return_max : 5492.27099609375\n",
      "eval/return_min : 1072.2362060546875\n",
      "eval/ep_len_std : 230.77434866119762\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 203\n",
      "TimeSinceStart : 271288.7005548477\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 4000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 2878.86767578125\n",
      "eval_ep_len : 524.3\n",
      "eval/return_std : 1950.837158203125\n",
      "eval/return_max : 5726.4921875\n",
      "eval/return_min : 898.3707275390625\n",
      "eval/ep_len_std : 334.2541099223763\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 199\n",
      "TimeSinceStart : 314551.0667104721\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n",
      "\n",
      "************ Step 4500000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3881.350830078125\n",
      "eval_ep_len : 698.6\n",
      "eval/return_std : 1663.3714599609375\n",
      "eval/return_max : 5759.91357421875\n",
      "eval/return_min : 958.0482177734375\n",
      "eval/ep_len_std : 296.6041806853032\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 180\n",
      "TimeSinceStart : 358750.6856930256\n",
      "Done logging...\n",
      "\n",
      "\n",
      "************ Step 5000000 ************\n",
      "\n",
      "Collecting data for eval...\n",
      "eval_return : 3203.36181640625\n",
      "eval_ep_len : 554.4\n",
      "eval/return_std : 1646.893798828125\n",
      "eval/return_max : 5815.994140625\n",
      "eval/return_min : 692.9907836914062\n",
      "eval/ep_len_std : 282.33852021996574\n",
      "eval/ep_len_max : 1000\n",
      "eval/ep_len_min : 137\n",
      "TimeSinceStart : 402418.64735126495\n",
      "Done logging...\n",
      "\n",
      "Collecting video rollouts...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# executing for about 111.7 hr (on localhost CPU, i5-12400)\n",
    "%run cs285/scripts/run_hw3_sac.py -cfg experiments/sac/humanoid_redq_reparametrize.yaml \\\n",
    "    --video_log_freq 1_000_000 --num_render_trajectories 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f1a57-4a44-422b-96b2-a567a7e244bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db248b3-a257-4bc4-b9be-5371c7f00dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir data/hw3_sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981dc2a-0341-4892-bc6e-b11683ba030e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
